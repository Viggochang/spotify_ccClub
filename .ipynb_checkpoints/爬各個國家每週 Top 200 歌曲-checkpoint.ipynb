{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "# 要爬的網址、api\n",
    "spotify = 'https://spotifycharts.com/'\n",
    "track_api = 'https://api.spotify.com/v1/tracks'\n",
    "feature_api = 'https://api.spotify.com/v1/audio-features'\n",
    "artists_api = 'https://api.spotify.com/v1/artists'\n",
    "\n",
    "'''\n",
    "要爬的國家\n",
    "'''\n",
    "r = requests.get('https://spotifycharts.com/regional/tw/weekly/latest')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "countries = [(c['data-value'], c.text) for c in soup.find('div', {'class': 'chart-filters-list'}).find('div', {'data-type':'country'}).find('ul').findAll('li')]\n",
    "countries_failed = []\n",
    "print(\"取得所有國家\")\n",
    "\n",
    "for region, country in countries:\n",
    "    \n",
    "    try:\n",
    "        time_start = dt.datetime.now()\n",
    "        print('===================================================')\n",
    "        print(f'{country} start!!')\n",
    "\n",
    "        \n",
    "        '''\n",
    "        爬每週 top200 的名單\n",
    "        '''\n",
    "        fri = dt.date(2020, 11, 27)\n",
    "        track_ids, w = [], 0\n",
    "        \n",
    "        # 計算總共有幾週可以爬\n",
    "        r = requests.get(f'https://spotifycharts.com/regional/{region}/weekly/latest')\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        weeks = len(soup.find('div', {'class': 'chart-filters-list'}).find('div', {'data-type':'date'}).find('ul').findAll('li'))\n",
    "        print(f'總共有{weeks}週')\n",
    "\n",
    "        while w < weeks:  \n",
    "            end, start = str(fri - dt.timedelta(days = 7*w)), str(fri - dt.timedelta(days = 7*(w+1)))\n",
    "            week = f'{start}--{end}'\n",
    "            w += 1  \n",
    "\n",
    "            # 爬該週的top200名單\n",
    "            url = f'{spotify}regional/{region}/weekly/{week}/download' \n",
    "            r = requests.get(url)\n",
    "            table = r.text.split('\\n')[2:-1]\n",
    "\n",
    "            # 整理 top200 track_ids\n",
    "            _ = [track.split(',')[-1].split('/')[-1] for track in table]\n",
    "            track_ids += _\n",
    "\n",
    "        track_ids = list(set(track_ids)) # 只取不重複的歌\n",
    "        print(f'取得歌曲id 共有{len(track_ids)}首歌')\n",
    "        \n",
    "\n",
    "        '''\n",
    "        爬 track_api 和 feature_api\n",
    "        '''\n",
    "        # 獲得 access_token (時間到會失效，每爬一個國家就重取一次token)\n",
    "        CLIENT_ID = 'ad0d8699855a4e72b183657dc0f7d55a'\n",
    "        CLIENT_SECRET = '3e66a60843e34360add3d4246c34fc52'\n",
    "        AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "        auth_response = requests.post(AUTH_URL, {'grant_type': 'client_credentials', 'client_id': CLIENT_ID, 'client_secret': CLIENT_SECRET,})\n",
    "        access_token = auth_response.json()['access_token']  # 取得token\n",
    "        headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "        data = pd.DataFrame(columns = ['track', 'feature'])\n",
    "        track, feature = [], []\n",
    "        i = 0 \n",
    "        while i < len(track_ids):\n",
    "            ids_t = ','.join(track_ids[i : i+50])  # tracks 一次最多50筆\n",
    "            track += requests.get(track_api, params = {'ids':ids_t}, headers = headers).json()['tracks']\n",
    "\n",
    "            if i%100 == 0:\n",
    "                ids_f = ','.join(track_ids[i:i+100])  # audio-features 一次最多100筆\n",
    "                feature += requests.get(feature_api, params = {'ids':ids_f}, headers = headers).json()['audio_features']\n",
    "\n",
    "            i += 50\n",
    "\n",
    "        data = pd.concat([data, pd.DataFrame(zip(track, feature), columns = ['track', 'feature'])], axis = 0)\n",
    "\n",
    "        \n",
    "        '''\n",
    "        把爬蟲爬到的東西分到各個column裡\n",
    "        '''\n",
    "        # track_api 爬到的東西\n",
    "        _ = [('track_name', 'name'), ('track_id', 'id'), ('popularity', 'popularity')]\n",
    "        for col, fea in _:\n",
    "            data[col] = data['track'].apply(lambda x: x[fea])\n",
    "        _ = [('album_name', 'name'), ('album_id', 'id'), ('release_date', 'release_date')] \n",
    "        for col, fea in _:\n",
    "            data[col] = data['track'].apply(lambda x: x['album'][fea])\n",
    "        _ = [('artist_name', 'name'), ('artist_id', 'id')]    \n",
    "        for col, fea in _:\n",
    "            data[col] = data['track'].apply(lambda x: x['artists'][0][fea])\n",
    "\n",
    "        # feature_api 爬到的東西    \n",
    "        features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms', 'time_signature']\n",
    "        for key in features:\n",
    "            data[key] = data['feature'].apply(lambda x:x[key])\n",
    "\n",
    "        print('取得track_api、feature_api資料')    \n",
    "\n",
    "        \n",
    "        '''\n",
    "        從 artists_api 取得 genres 資訊\n",
    "        '''    \n",
    "        # 建立 artists_id、genres 對照表\n",
    "        artist_genres = dict()\n",
    "        artists_ids = list(data['artist_id'].unique())\n",
    "\n",
    "        i = 0\n",
    "        while i < len(artists_ids):\n",
    "            ids = ','.join(artists_ids[i:i+50]) # artists 一次最多50筆\n",
    "\n",
    "            r = requests.get(artists_api, params = {'ids':ids}, headers = headers)\n",
    "            artist_genres.update({artist['id']:artist['genres'] for artist in r.json()['artists']})\n",
    "\n",
    "            i += 50 \n",
    "\n",
    "        # 取得 genres\n",
    "        data['genres'] = data['artist_id'].map(artist_genres)\n",
    "        print('取得genre資料')\n",
    "\n",
    "        # 加上 country 資訊\n",
    "        data['country'] = country\n",
    "        \n",
    "        '''\n",
    "        輸出檔案\n",
    "        '''\n",
    "        #data[['track', 'feature']].to_csv(f'C:\\\\Users\\\\7334\\\\data_track_feature\\\\data_t_f_{country}', index = False)\n",
    "        data = data.drop(['track', 'feature'], axis = 1)\n",
    "        data.to_csv(f'C:\\\\Users\\\\7334\\\\data\\\\data_{country}.csv', index = False)\n",
    "        \n",
    "        print(dt.datetime.now() - time_start)\n",
    "        print(f'{country} finish!!')\n",
    "        \n",
    "    except:\n",
    "        countries_failed.append(country)\n",
    "        print(dt.datetime.now() - time_start)\n",
    "        print(f'{country} failed!!')\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
