{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "取得所有國家\n",
      "===================================================\n",
      "Global start!!\n",
      "總共有203週\n",
      "取得歌曲id 共有3951首歌\n",
      "取得track_api、feature_api資料\n",
      "取得genre資料\n",
      "0:04:40.152779\n",
      "Global finish!!\n",
      "===================================================\n",
      "United States start!!\n",
      "總共有205週\n",
      "取得歌曲id 共有4687首歌\n",
      "取得track_api、feature_api資料\n",
      "取得genre資料\n",
      "0:03:45.781073\n",
      "United States finish!!\n",
      "===================================================\n",
      "United Kingdom start!!\n",
      "總共有205週\n",
      "取得歌曲id 共有4098首歌\n",
      "取得track_api、feature_api資料\n",
      "取得genre資料\n",
      "0:05:25.051951\n",
      "United Kingdom finish!!\n",
      "===================================================\n",
      "Andorra start!!\n",
      "總共有40週\n",
      "取得歌曲id 共有153首歌\n",
      "取得track_api、feature_api資料\n",
      "取得genre資料\n",
      "0:00:53.688730\n",
      "Andorra finish!!\n",
      "===================================================\n",
      "Argentina start!!\n",
      "總共有205週\n",
      "0:00:40.029138\n",
      "Argentina failed!!\n",
      "===================================================\n",
      "Austria start!!\n",
      "總共有205週\n",
      "0:00:21.454045\n",
      "Austria failed!!\n",
      "===================================================\n",
      "Australia start!!\n",
      "0:00:00.146395\n",
      "Australia failed!!\n",
      "===================================================\n",
      "Belgium start!!\n",
      "總共有205週\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "# 要爬的網址、api\n",
    "spotify = 'https://spotifycharts.com/'\n",
    "track_api = 'https://api.spotify.com/v1/tracks'\n",
    "feature_api = 'https://api.spotify.com/v1/audio-features'\n",
    "artists_api = 'https://api.spotify.com/v1/artists'\n",
    "\n",
    "\n",
    "'''\n",
    "設定要爬的國家\n",
    "'''\n",
    "r = requests.get('https://spotifycharts.com/regional/tw/weekly/latest')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "countries = [(c['data-value'], c.text) for c in soup.find('div', {'class': 'chart-filters-list'}).find('div', {'data-type':'country'}).find('ul').findAll('li')]\n",
    "countries_failed = []\n",
    "print(\"取得所有國家\")\n",
    "\n",
    "for region, country in countries:\n",
    "    \n",
    "    try:\n",
    "        time_start = dt.datetime.now()\n",
    "        print('===================================================')\n",
    "        print(f'{country} start!!')\n",
    "\n",
    "        \n",
    "        '''\n",
    "        爬每週 top200 的名單\n",
    "        '''\n",
    "        track_ids, w = [], 0\n",
    "\n",
    "        r = requests.get(f'https://spotifycharts.com/regional/{region}/weekly/latest')\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        weeks = [s['data-value'] for s in soup.find('div', {'class': 'chart-filters-list'}).find('div', {'data-type':'date'}).find('ul').findAll('li')]\n",
    "        print(f'總共有{len(weeks)}週')\n",
    "\n",
    "        while w < len(weeks):  \n",
    "\n",
    "            # 爬該週的top200名單\n",
    "            url = f'{spotify}regional/{region}/weekly/{weeks[w]}/download' \n",
    "            r = requests.get(url)\n",
    "            table = r.text.split('\\n')[2:-1] # 網站上爬下來的東西頭尾都是說明，不要取\n",
    "\n",
    "            # 整理 top200 track_ids\n",
    "            _ = [track.split(',')[-1].split('/')[-1] for track in table]\n",
    "            track_ids += _\n",
    "            w += 1\n",
    "\n",
    "        track_ids = list(set(track_ids)) # 只取不重複的歌\n",
    "        if '' in track_ids:\n",
    "            track_ids.remove('')\n",
    "        print(f'取得歌曲id 共有{len(track_ids)}首歌')\n",
    "\n",
    "        \n",
    "        '''\n",
    "        爬 track_api 和 feature_api\n",
    "        '''\n",
    "        # 獲得 access_token (時間到會失效，每爬一個國家就重取一次token)\n",
    "        CLIENT_ID = 'ad0d8699855a4e72b183657dc0f7d55a'\n",
    "        CLIENT_SECRET = '3e66a60843e34360add3d4246c34fc52'\n",
    "        AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "        auth_response = requests.post(AUTH_URL, {'grant_type': 'client_credentials', 'client_id': CLIENT_ID, 'client_secret': CLIENT_SECRET,})\n",
    "        access_token = auth_response.json()['access_token']  # 取得token\n",
    "        headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "        data = pd.DataFrame(columns = ['track', 'feature'])\n",
    "        track, feature = [], []\n",
    "        i = 0 \n",
    "        while i < len(track_ids):\n",
    "            ids_t = ','.join(track_ids[i : i+50])  # tracks 一次最多50筆\n",
    "            track += requests.get(track_api, params = {'ids':ids_t}, headers = headers).json()['tracks']\n",
    "\n",
    "            if i%100 == 0:\n",
    "                ids_f = ','.join(track_ids[i:i+100])  # audio-features 一次最多100筆\n",
    "                feature += requests.get(feature_api, params = {'ids':ids_f}, headers = headers).json()['audio_features']\n",
    "\n",
    "            i += 50\n",
    "\n",
    "        data = pd.concat([data, pd.DataFrame(zip(track, feature), columns = ['track', 'feature'])], axis = 0)\n",
    "        data = data.dropna()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        把爬蟲爬到的東西分到各個column裡\n",
    "        '''\n",
    "        # track_api 爬到的東西\n",
    "        _ = [('track_name', 'name'), ('track_id', 'id'), ('popularity', 'popularity')]\n",
    "        for col, fea in _:\n",
    "            data[col] = data['track'].apply(lambda x: x[fea])\n",
    "        _ = [('album_name', 'name'), ('album_id', 'id'), ('release_date', 'release_date')] \n",
    "        for col, fea in _:\n",
    "            data[col] = data['track'].apply(lambda x: x['album'][fea])\n",
    "        _ = [('artist_name', 'name'), ('artist_id', 'id')]    \n",
    "        for col, fea in _:\n",
    "            data[col] = data['track'].apply(lambda x: x['artists'][0][fea])\n",
    "\n",
    "        # feature_api 爬到的東西    \n",
    "        features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms', 'time_signature']\n",
    "        for key in features:\n",
    "            data[key] = data['feature'].apply(lambda x:x[key])\n",
    "\n",
    "        print('取得track_api、feature_api資料')    \n",
    "\n",
    "        \n",
    "        '''\n",
    "        從 artists_api 取得 genres 資訊\n",
    "        '''    \n",
    "        # 建立 artists_id、genres 對照表\n",
    "        artist_genres = dict()\n",
    "        artists_ids = list(data['artist_id'].unique())\n",
    "\n",
    "        i = 0\n",
    "        while i < len(artists_ids):\n",
    "            ids = ','.join(artists_ids[i:i+50]) # artists 一次最多50筆\n",
    "\n",
    "            r = requests.get(artists_api, params = {'ids':ids}, headers = headers)\n",
    "            artist_genres.update({artist['id']:artist['genres'] for artist in r.json()['artists']})\n",
    "\n",
    "            i += 50 \n",
    "\n",
    "        # 取得 genres\n",
    "        data['genres'] = data['artist_id'].map(artist_genres)\n",
    "        print('取得genre資料')\n",
    "\n",
    "        # 加上 country 資訊\n",
    "        data['country'] = country\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        輸出檔案\n",
    "        '''\n",
    "        # data[['track', 'feature']].to_csv(f'C:\\\\Users\\\\7334\\\\data_track_feature\\\\data_t_f_{country}', index = False)\n",
    "        #data = data.drop(['track', 'feature'], axis = 1)\n",
    "        #data.to_csv(f'C:\\\\Users\\\\7334\\\\data\\\\data_{country}.csv', index = False)\n",
    "        \n",
    "        print(dt.datetime.now() - time_start)\n",
    "        print(f'{country} finish!!')\n",
    "        \n",
    "    except:\n",
    "        countries_failed.append(country)\n",
    "        print(dt.datetime.now() - time_start)\n",
    "        print(f'{country} failed!!')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global',\n",
       " 'Andorra',\n",
       " 'Bolivia',\n",
       " 'Ecuador',\n",
       " 'Iceland',\n",
       " 'Netherlands',\n",
       " 'Panama',\n",
       " 'Peru',\n",
       " 'Philippines']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('global', 'Global'),\n",
       " ('us', 'United States'),\n",
       " ('gb', 'United Kingdom'),\n",
       " ('ad', 'Andorra'),\n",
       " ('ar', 'Argentina'),\n",
       " ('at', 'Austria'),\n",
       " ('au', 'Australia'),\n",
       " ('be', 'Belgium'),\n",
       " ('bg', 'Bulgaria'),\n",
       " ('bo', 'Bolivia'),\n",
       " ('br', 'Brazil'),\n",
       " ('ca', 'Canada'),\n",
       " ('ch', 'Switzerland'),\n",
       " ('cl', 'Chile'),\n",
       " ('co', 'Colombia'),\n",
       " ('cr', 'Costa Rica'),\n",
       " ('cy', 'Cyprus'),\n",
       " ('cz', 'Czech Republic'),\n",
       " ('de', 'Germany'),\n",
       " ('dk', 'Denmark'),\n",
       " ('do', 'Dominican Republic'),\n",
       " ('ec', 'Ecuador'),\n",
       " ('ee', 'Estonia'),\n",
       " ('es', 'Spain'),\n",
       " ('fi', 'Finland'),\n",
       " ('fr', 'France'),\n",
       " ('gr', 'Greece'),\n",
       " ('gt', 'Guatemala'),\n",
       " ('hk', 'Hong Kong'),\n",
       " ('hn', 'Honduras'),\n",
       " ('hu', 'Hungary'),\n",
       " ('id', 'Indonesia'),\n",
       " ('ie', 'Ireland'),\n",
       " ('il', 'Israel'),\n",
       " ('in', 'India'),\n",
       " ('is', 'Iceland'),\n",
       " ('it', 'Italy'),\n",
       " ('jp', 'Japan'),\n",
       " ('lt', 'Lithuania'),\n",
       " ('lu', 'Luxembourg'),\n",
       " ('lv', 'Latvia'),\n",
       " ('mx', 'Mexico'),\n",
       " ('my', 'Malaysia'),\n",
       " ('ni', 'Nicaragua'),\n",
       " ('nl', 'Netherlands'),\n",
       " ('no', 'Norway'),\n",
       " ('nz', 'New Zealand'),\n",
       " ('pa', 'Panama'),\n",
       " ('pe', 'Peru'),\n",
       " ('ph', 'Philippines'),\n",
       " ('pl', 'Poland'),\n",
       " ('pt', 'Portugal'),\n",
       " ('py', 'Paraguay'),\n",
       " ('ro', 'Romania'),\n",
       " ('ru', 'Russian Federation'),\n",
       " ('se', 'Sweden'),\n",
       " ('sg', 'Singapore'),\n",
       " ('sk', 'Slovakia'),\n",
       " ('sv', 'El Salvador'),\n",
       " ('th', 'Thailand'),\n",
       " ('tr', 'Turkey'),\n",
       " ('tw', 'Taiwan'),\n",
       " ('ua', 'Ukraine'),\n",
       " ('uy', 'Uruguay'),\n",
       " ('vn', 'Viet Nam'),\n",
       " ('za', 'South Africa')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "r = requests.get('https://spotifycharts.com/regional/tw/weekly/latest')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "countries = [(c['data-value'], c.text) for c in soup.find('div', {'class': 'chart-filters-list'}).find('div', {'data-type':'country'}).find('ul').findAll('li')]\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213058\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "data = pd.DataFrame(columns = cols)\n",
    "for region, country in countries:\n",
    "    d = pd.read_csv(f'C:\\\\Users\\\\7334\\\\data\\\\data_{country}.csv')\n",
    "    data = pd.concat([data, d])\n",
    "    count += len(d)\n",
    "print(count)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:\\\\Users\\\\7334\\\\data\\\\data_total.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60122"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "len(pd.unique(data['track_id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
